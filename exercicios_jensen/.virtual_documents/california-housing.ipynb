%matplotlib widget
import numpy as np
import matplotlib.pyplot as plt 

import pandas as pd  
import seaborn as sns

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from functions import getRmse

# enfim, como não teve como usar o da boston. vai esse.


housing = fetch_california_housing()
california = pd.DataFrame(housing.data,columns=housing.feature_names)
california.head()


california.isna().sum()


correlation_matrix = california.corr().round(2)

sns.heatmap(data=correlation_matrix,annot=True,cmap='coolwarm')





target = california['MedInc']
features = ["AveRooms","AveBedrms"]





X = pd.DataFrame(np.c_[california[features[0]],california[features[1]]],columns=features)
Y = target


# separando os dados em de teste e de treino

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=.2,random_state=5)
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)


# agora usamos as funcionalidades de regressão linear

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler,MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score


model = Pipeline([
    ('std_scaler',StandardScaler()),
    ('poly',PolynomialFeatures(3)),
    ('lin_reg',LinearRegression())
])

model.fit(X_train,Y_train)


y_train_predict = model.predict(X_train)
rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))
r2 = r2_score(Y_train, y_train_predict)


print("The model performance for training set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))
print("\n")


y_test_predict = model.predict(X_test)
rmse = (np.sqrt(mean_squared_error(Y_test,y_test_predict)))
r2 = r2_score(Y_test,y_test_predict)

print("The model performance for testing set")
print("--------------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))





plt.close()
fig, axes = plt.subplots(nrows=1,ncols=2,subplot_kw={'projection': '3d'},figsize=(15,4))


axes[0].scatter(X_train['AveRooms'],X_train['AveBedrms'],Y_train,label="dados de treino")
axes[0].scatter(X_train['AveRooms'],X_train['AveBedrms'],model.predict(X_train),label='dados gerados pelo modelo')
axes[0].set_title("Dados de treino")

axes[0].set_xlabel("AveRooms")
axes[0].set_ylabel('AveBedrms')
axes[0].set_zlabel('Median income')
axes[0].legend()

axes[1].scatter(X_test['AveRooms'],X_test['AveBedrms'],Y_test,label="dados de teste")
axes[1].scatter(X_test['AveRooms'],X_test['AveBedrms'],model.predict(X_test),label='dados gerados pelo modelo')
axes[1].set_title("Dados de teste")

axes[1].set_xlabel("AveRooms")
axes[1].set_ylabel('AveBedrms')
axes[1].set_zlabel('Median income')
axes[1].legend()

plt.tight_layout()


max_degree = 30
rmses_train = np.zeros((max_degree))
rmses_test = np.zeros((max_degree))
degrees = np.arange(1,max_degree+1,1)

for i in range(max_degree):
    rmse_train,rmse_test = getRmse(X_train,Y_train,X_test,Y_test,i)
    rmses_train[i] += rmse_train
    rmses_test[i] += rmse_test



plt.close()
radius = 20
plt.scatter(degrees,rmses_train,label='Dados de treino',s=radius)
plt.scatter(degrees,rmses_test,label='Dados de teste',s=radius)
plt.plot(degrees,rmses_train,label='Dados de treino')
plt.plot(degrees,rmses_test,label='Dados de teste')

plt.xlabel('Complexidade')
plt.ylabel('RMSE')
plt.title('Complexidade vs Erro')
plt.grid(True)
plt.legend()
plt.show()


plt.close()
plt.scatter(degrees,np.log(rmses_train),label='Dados de treino',s=radius)
plt.scatter(degrees,np.log(rmses_test),label='Dados de teste',s=radius)
plt.plot(degrees,np.log(rmses_train),label='Dados de treino')
plt.plot(degrees,np.log(rmses_test),label='Dados de teste')

plt.xlabel('Complexidade')
plt.ylabel('$\\log$ RMSE')
plt.title('Complexidade vs log Erro')
plt.grid(True)
plt.legend()
plt.show()
