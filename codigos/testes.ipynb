{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "não é uma lista\n"
     ]
    }
   ],
   "source": [
    "lista = 2\n",
    "if type(lista) != list:\n",
    "    print('não é uma lista')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste1 1\n",
      "teste2 2\n"
     ]
    }
   ],
   "source": [
    "dicio = {'teste1':1,'teste2':2}\n",
    "for name, value in dicio.items():\n",
    "    print(name,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{d}{d x} f{\\left(x \\right)} = f{\\left(x \\right)}$"
      ],
      "text/plain": [
       "Eq(Derivative(f(x), x), f(x))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "x,p,A = sp.symbols('x,p,A')\n",
    "\n",
    "f = sp.Function('f')(x)\n",
    "#A = sp.Function('A')(x)\n",
    "N = sp.Function('N')(x,p)\n",
    "\n",
    "expr = sp.Eq(f.diff(x),f)\n",
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\partial}{\\partial x} \\left(A + x N{\\left(x,p \\right)}\\right) = A + x N{\\left(x,p \\right)}$"
      ],
      "text/plain": [
       "Eq(Derivative(A + x*N(x, p), x), A + x*N(x, p))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr.subs(f,A + x*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eq(A + x*N(x, p), x*Derivative(N(x, p), x) + N(x, p))\n"
     ]
    }
   ],
   "source": [
    "print(sp.simplify(expr.subs(f,A + x*N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Mul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Criação e treinamento do modelo\u001b[39;00m\n\u001b[1;32m     58\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralODEModel(num_hidden_neurons)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Solução aproximada pelo modelo\u001b[39;00m\n\u001b[1;32m     62\u001b[0m g_nn \u001b[38;5;241m=\u001b[39m g_analytic(x[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m model(x)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[12], line 36\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, x, num_iter, learning_rate, g0, gamma)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iter):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 36\u001b[0m         cost \u001b[38;5;241m=\u001b[39m \u001b[43mcost_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(cost, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     38\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "Cell \u001b[0;32mIn[12], line 24\u001b[0m, in \u001b[0;36mcost_function\u001b[0;34m(model, x, g0, gamma)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     23\u001b[0m     tape\u001b[38;5;241m.\u001b[39mwatch(x)\n\u001b[0;32m---> 24\u001b[0m     g_trial \u001b[38;5;241m=\u001b[39m g0 \u001b[38;5;241m+\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Solução aproximada\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     dg_dx \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(g_trial, x)  \u001b[38;5;66;03m# Derivada da solução\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     g_rhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mgamma \u001b[38;5;241m*\u001b[39m g_trial  \u001b[38;5;66;03m# Lado direito da EDO\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/regression/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/regression/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Mul] name: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Definindo a classe para o modelo usando Subclassing do Keras\n",
    "class NeuralODEModel(keras.Model):\n",
    "    def __init__(self, num_hidden_neurons):\n",
    "        super(NeuralODEModel, self).__init__()\n",
    "        # Camada oculta\n",
    "        self.hidden = keras.layers.Dense(num_hidden_neurons, activation='sigmoid', use_bias=True)\n",
    "        # Camada de saída\n",
    "        self.output_layer = keras.layers.Dense(1, activation=None, use_bias=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.expand_dims(x, -1)  # Adicionar uma dimensão extra\n",
    "        h = self.hidden(x)\n",
    "        out = self.output_layer(h)\n",
    "        return tf.squeeze(out, -1)  # Remover a dimensão extra\n",
    "\n",
    "# Função de custo\n",
    "def cost_function(model, x, g0=10, gamma=2):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        g_trial = g0 + x * model(x)  # Solução aproximada\n",
    "        dg_dx = tape.gradient(g_trial, x)  # Derivada da solução\n",
    "        g_rhs = -gamma * g_trial  # Lado direito da EDO\n",
    "        cost = tf.reduce_mean(tf.square(dg_dx - g_rhs))  # Erro quadrático médio\n",
    "    return cost\n",
    "\n",
    "# Treinamento do modelo\n",
    "def train_model(model, x, num_iter, learning_rate, g0=10, gamma=2):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            cost = cost_function(model, x, g0, gamma)\n",
    "        gradients = tape.gradient(cost, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        if i % (num_iter // 10) == 0 or i == num_iter - 1:\n",
    "            print(f\"Iteration {i+1}/{num_iter}, Cost: {cost.numpy():.6f}\")\n",
    "\n",
    "# Solução analítica para comparação\n",
    "def g_analytic(x, gamma=2, g0=10):\n",
    "    return g0 * np.exp(-gamma * x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Dados de entrada\n",
    "    N = 10\n",
    "    x = tf.linspace(0, 1, N)[:,tf.newaxis]\n",
    "\n",
    "    # Configuração do modelo\n",
    "    num_hidden_neurons = 10\n",
    "    num_iter = 1000\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # Criação e treinamento do modelo\n",
    "    model = NeuralODEModel(num_hidden_neurons)\n",
    "    train_model(model, x, num_iter, learning_rate)\n",
    "\n",
    "    # Solução aproximada pelo modelo\n",
    "    g_nn = g_analytic(x[0]) + x.T * model(x).numpy()\n",
    "\n",
    "    # Solução analítica\n",
    "    g_exact = g_analytic(x)\n",
    "\n",
    "    # Comparação\n",
    "    max_diff = np.max(np.abs(g_nn - g_exact))\n",
    "    print(f\"Max absolute difference: {max_diff}\")\n",
    "\n",
    "    # Plotagem dos resultados\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(x, g_exact, label='Analytical Solution')\n",
    "    plt.plot(x, g_nn, label='Neural Network Solution')\n",
    "    plt.legend()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('g(x)')\n",
    "    plt.title('ODE Solution: Analytical vs Neural Network')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # Deve retornar uma versão compatível, como '2.x'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
